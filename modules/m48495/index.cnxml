<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Implementation: Integration</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m48495</md:content-id>
  <md:title>Implementation: Integration</md:title>
  <md:abstract/>
  <md:uuid>2608cd5c-ce54-4621-9b31-b1f623361a1a</md:uuid>
</metadata>
<featured-links>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit below.
       Changes to the links section in the source will not be saved. -->
    <link-group type="example">
      <link url="http://cnx.org/Members/xc7/module.2013-12-18.0390523267" strength="3">Implementation: Detecting a Hit</link>
      <link url="http://cnx.org/Members/xc7/module.2013-12-18.5969651848" strength="3">Testing, Conclusion and Future Work</link>
    </link-group>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit above.
       Changes to the links section in the source will not be saved. -->
</featured-links>
<content>
    <section id="eip-183"><title>Connection between audio and video</title><para id="eip-10">
A webcam will videotape the paper and stick movement; then, a computer will process the images to determine the drum stick positions. Once the microphone detects the audio signal created by the player hitting the drums on the paper, the visual information showing the current position of the drum stick is used to generate the correct sounds.
</para></section><section id="eip-881"><title>Reduce processing delay</title><para id="eip-383">
Whether the stick hits the paper or not, we processed the snapshots and saved the current stick location in an array. Only when the stick hits the paper, which is detected by the impulse from the microphone, we took out the position information to generate the correct sounds.
</para></section><section id="eip-990"><title>Sound division</title><para id="eip-559">
Below is how we divide our paper. Each part corresponds to a unique sound. In total there are four parts. The stick position determines which sound to play by the computer.
</para></section><figure id="import-auto-id1171529947523">
      <media id="import-auto-id1171542587409" alt="">
        <image mime-type="image/jpg" src="../../media/graphics1-a8d7.jpg" height="433" width="576"/>
      </media>
    </figure><code id="eip-957" display="block"><title>Playing different sounds</title>i=0;
playing=0;
sample_rate_devider=3;
while(1==1)
    i = i+1;
    if (sample_rate_devider==3)
        hitPosition = tracking(vidobj,edgePosition);
        sample_rate_devider=0;
    end
    
    sample_rate_devider=sample_rate_devider+1;
    
    pastData = sampleAudio(pastData,ai,dataLengthConstant);
    % if we got a audio trigger
    if(playing ~=0)
        playing=playing-1;
    else
        if(testImpulse(pastData,threshHold)==1)
            playing = 5;
            soundType = getWhichSound(hitPosition,edgePosition);
            %         makeSound(soundType);
            if (soundType==1)
                %play sound1
                sound(sound1,Fs1);
            elseif (soundType==2)
                %play sound 2
                sound(sound2,Fs2);
            elseif (soundType==3)
                %play sound 3
                sound(sound3,Fs3);
            else (soundType==4)
                %play sound 4
                sound(sound4,Fs4);
        end
        
        
    end
end
end</code></content>
</document>